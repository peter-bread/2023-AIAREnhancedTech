# 2023-AIAREnhancedTech

## Table of Contents
  - [AIAREnhancedTech](#2023-AIAREnhancedTech)
  - [Table of Contents](#Table-of-Contents)
  - [Project Summary](#Project-Summary)
  - [Ambitions for final product](#Ambitions-for-final-product)
  - [StakeHolders](#StakeHolders)
  - [Getting Started](#Getting-Started)
  - [Prerequisits](#Prerequisits)
  - [Technologies](#Technologies)
  - [Kanban Board](#Kanban-Board)
  - [Gantt Chart](#Gantt-Chart)
  - [License](#License)

## Project Summary

The project's objective is to develop a mobile application that leverages Augmented Reality technology to offer enhancements and supplementary information for Galasa Documentation.

### Ambitions for final product

We create a fully functional mobile application - a user can move their phone over Galasa documentation into the cameras frame and AR enhancement is shown. This enhancemnt involves providing more detail about the diagram with help of an AI assistant, it will also turn static digrams into moving and enhance the image to make it more visually appealing. The User will be able to ask quitions to the AI Assistant to gain more information.

Develop a fully functional mobile application that enriches a users their experience with Galasa Documentation through Augmented Reality. By simply moving their phone's camera over Galasa documentation, users will witness AR enhancements. These enhancements involve several key features:

1. **Detailed Information**: An AI assistant will provide in-depth explanations and context for diagrams, making complex information more understandable.

2. **Interactive Diagrams**: Static diagrams will come to life, offering dynamic representations that enhance understanding.

3. **Visual Appeal**: The application will improve the visual aesthetics of diagrams, making them more engaging and informative.

4. **Interactive Querying**: Users will have the ability to interact with the AI assistant by asking questions, enabling them to delve deeper into the subject matter.

Our mobile app transforms the way users interact with Galasa Documentation, providing an immersive and informative experience using Augmented Reality technology.

## StakeHolders
| Stakeholder | Name | Role |
|-|-|-|
|Clients| Jon Mc Namara & Stuart Walker | IBM employees - overseeing the project and delivering the project specification|
| Team | Zak Mansuri, Peter Sheehan, Ruoxin Chen, Louie Sinadjan | Developing the product |
| Test Engineers | | Using the mobile app, trying to undertand Galasa |

# Getting Started

## Prerequisits

* Download Xcode for Swift

## Technologies

* **Swift**  -  As a team, we have chosen to utilize the Swift programming language to develop our application. Swift is a modern, open-source programming language developed by Apple. Swift offers performance improvements over Objective-C and features a clean and concise syntax making it a popular choice for building iOS applications.
  
* **AR Kit 6**  -  ARKit is a software development framework by Apple that enables the creation of augmented reality (AR) experiences on iOS devices. ARKit has been used to develop a wide range of AR applications, including many educational tools.  It provides tools and resources for developers to seamlessly blend digital content with the real world through the device's camera and sensors.
  
* **IBM's AI Watson Speech to Text, Text to Speech**  -  IBM's Watson is an artificial intelligence system developed by IBM. Watson is powered by advanced machine learning and natural language processing algorithms. Watson Speech to Text and Text to Speech are services within IBM's Watson AI platform. We will look to harness Watsonâ€™s Text to Speech service to transform written text into lifelike speech, facilitating the applications interactive voice response systems.


## Kanban Board

* [Kanban Board](https://github.com/orgs/spe-uob/projects/137/)

## Gantt Chart

## Licence

No Licence Chosen
